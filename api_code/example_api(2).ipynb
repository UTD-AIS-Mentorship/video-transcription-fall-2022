{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kbk9VuDIK7te"
   },
   "source": [
    "# FIRST: Go to Runtime -> Change Runtime type -> GPU accelerated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ycp2tGL7LIra"
   },
   "source": [
    "This next codeblock installs an archived version of transformers\n",
    "\n",
    "installs datasets==1.16.1 for putting example datasets (might not be needed)\n",
    "\n",
    "bitsandbytes for tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDyXxk4hJ3zx",
    "outputId": "981fb696-733d-4320-df70-058e87f06a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.17.0.dev0\n",
      "Uninstalling transformers-4.17.0.dev0:\n",
      "  Successfully uninstalled transformers-4.17.0.dev0\n",
      "Collecting https://github.com/deniskamazur/transformers/archive/gpt-j-8bit.zip\n",
      "  Downloading https://github.com/deniskamazur/transformers/archive/gpt-j-8bit.zip\n",
      "\u001b[K     | 10.2 MB 4.0 MB/s\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (3.8.0)\n",
      "Requirement already satisfied: sacremoses in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (0.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (2022.9.13)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (6.0)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (1.23.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers==4.17.0.dev0) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.17.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers==4.17.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers==4.17.0.dev0) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers==4.17.0.dev0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers==4.17.0.dev0) (2022.9.24)\n",
      "Requirement already satisfied: click in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sacremoses->transformers==4.17.0.dev0) (8.1.3)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sacremoses->transformers==4.17.0.dev0) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from sacremoses->transformers==4.17.0.dev0) (1.2.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.17.0.dev0-py3-none-any.whl size=3653094 sha256=704c7f3690ae04d33cab53728449781efe27841b2f402533f4dbd9698ea7fcdb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mqpxp1za/wheels/5c/94/2d/f40e0fc8c0fa3b5e042a8ce31f18fb494ff4dad8a2134121b5\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.17.0.dev0\n",
      "Requirement already satisfied: datasets==1.16.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.16.1)\n",
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (1.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (0.10.1)\n",
      "Requirement already satisfied: aiohttp in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (1.23.4)\n",
      "Requirement already satisfied: multiprocess in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (0.70.13)\n",
      "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (21.3)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (9.0.0)\n",
      "Requirement already satisfied: dill in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (3.1.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (2022.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from datasets==1.16.1) (2.28.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets==1.16.1) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets==1.16.1) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets==1.16.1) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets==1.16.1) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets==1.16.1) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets==1.16.1) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from aiohttp->datasets==1.16.1) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging->datasets==1.16.1) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.16.1) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.16.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.16.1) (1.26.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->datasets==1.16.1) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas->datasets==1.16.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets==1.16.1) (1.16.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.35.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers && pip install --no-cache-dir https://github.com/deniskamazur/transformers/archive/gpt-j-8bit.zip\n",
    "!pip install datasets==1.16.1 # for loading example datasets (might not be needed)\n",
    "!pip install bitsandbytes # for tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgRgqz3VMCja"
   },
   "source": [
    "# Below loads model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "86U7y3C8KEWB"
   },
   "outputs": [],
   "source": [
    "def gpu_model():\n",
    "  import torch\n",
    "  import transformers\n",
    "  from transformers.models.gptj import GPTJForCausalLM #gptj only?\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu' # select gpu otherwise use cpu\n",
    "  tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\") #loads original 6B model\n",
    "  model = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True).to(device) #use pretrained 8bit \"shrunken\" model used for low memory aka using for google colab\n",
    "  return [device,tokenizer,model]\n",
    "  \n",
    "def cpu_model():\n",
    "  import torch\n",
    "  import transformers\n",
    "  from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu' # select gpu otherwise use cpu\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "  model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "  return [device,tokenizer,model]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAX5epM_MOMR"
   },
   "source": [
    "# Install youtubetranscript api for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHbKbC1sL_Xq",
    "outputId": "f5c06417-a575-4791-9086-820818045e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_transcript_api in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.4.4)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from youtube_transcript_api) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->youtube_transcript_api) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->youtube_transcript_api) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->youtube_transcript_api) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->youtube_transcript_api) (1.26.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cIuztjAPTme"
   },
   "source": [
    "# Summary pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4SWK6SrNJhv",
    "outputId": "e9bdc623-a20f-4b9b-dc2f-70d27afb59dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.85.1)\n",
      "Requirement already satisfied: nest-asyncio in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.5.5)\n",
      "Requirement already satisfied: pyngrok in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (5.1.0)\n",
      "Requirement already satisfied: uvicorn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from fastapi) (1.10.2)\n",
      "Requirement already satisfied: starlette==0.20.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from fastapi) (0.20.4)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from starlette==0.20.4->fastapi) (4.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from starlette==0.20.4->fastapi) (3.6.2)\n",
      "Requirement already satisfied: PyYAML in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyngrok) (6.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from uvicorn) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi) (3.4)\n",
      "Authtoken saved to configuration file: /home/studio-lab-user/.ngrok2/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
    "!ngrok authtoken 2B39YnQIGeHG0FeFnLIgkPVJmdq_3eXfqZe6aXCu8YkFZ2nQ9\n",
    "\n",
    "# !pip install flask\n",
    "# !pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyB2T7RRUOoB",
    "outputId": "b406c568-b5ce-4026-e761-499d9679c1e9",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[?47h\u001b[?1h\u001b=\u0002\u0007\u001b[H\u001b[2J\u001b[m\u001b[38;5;6m\u001b[48;5;16m\u001b[1m\u001b[1;1Hngrok\u001b[m\u001b[38;5;16m\u001b[48;5;16m \u001b[m\u001b[38;5;7m\u001b[48;5;16mby\u001b[m\u001b[38;5;16m\u001b[48;5;16m \u001b[m\u001b[38;5;6m\u001b[48;5;16m\u001b[1m@inconshreveable\u001b[m\u001b[38;5;16m\u001b[48;5;16m                                       \u001b[m\u001b[38;5;7m\u001b[48;5;16m(Ctrl+C to quit)\u001b[m\u001b[38;5;16m\u001b[48;5;16m\u001b[2;1H                                                                                \u001b[m\u001b[38;5;6m\u001b[48;5;16m\u001b[3;1HSession Status                connecting\u001b[m\u001b[38;5;16m\u001b[48;5;16m                                        \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[4;1HVersion                       2.3.40\u001b[m\u001b[38;5;16m\u001b[48;5;16m                                            \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[5;1HRegion                        United States (us)\u001b[m\u001b[38;5;16m\u001b[48;5;16m                                \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[6;1HWeb Interface                 http://127.0.0.1:4040\u001b[m\u001b[38;5;16m\u001b[48;5;16m                             \u001b[7;1H                                                                                \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[8;1HConnections                   ttl     opn     rt1     rt5     p50     p90     \u001b[m\u001b[38;5;16m\u001b[48;5;16m  \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[9;1H                              0       0       0.00    0.00    0.00    0.00    \u001b[m\u001b[38;5;16m\u001b[48;5;16m  \u001b[10;1H                                                                                \u001b[11;1H                                                                                \u001b[12;1H                                                                                \u001b[13;1H                                                                                \u001b[14;1H                                                                                \u001b[15;1H                                                                                \u001b[16;1H                                                                                \u001b[17;1H                                                                                \u001b[18;1H                                                                                \u001b[19;1H                                                                                \u001b[20;1H                                                                                \u001b[21;1H                                                                                \u001b[22;1H                                                                                \u001b[23;1H                                                                                \u001b[24;1H                                                                                \u001b[m\u001b[38;5;2m\u001b[48;5;16m\u001b[3;1HSession Status                online\u001b[m\u001b[38;5;16m\u001b[48;5;16m    \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[4;1HAccount\u001b[4;31Hswagdisimo523@gmail.com (Plan: Free)\u001b[5;1HV\u001b[5;3Hrsion\u001b[5;31H2.3.40\u001b[m\u001b[38;5;16m\u001b[48;5;16m            \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[6;1HR\u001b[6;3Hgio\u001b[6;7H       \u001b[6;31HUnited States (us)\u001b[m\u001b[38;5;16m\u001b[48;5;16m   \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[7;1HWeb Interface                 http://127.0.0.1:4040\u001b[8;1HF\u001b[8;3Hrward\u001b[8;9Hng \u001b[8;31Hh\u001b[8;33Htps://ef83-3-20-229-229.ngrok.io ->\u001b[8;69Hhttp://local\u001b[m\u001b[38;5;16m\u001b[48;5;16m\u001b[9;1H                                                                              \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[10;1HConnections                   ttl     opn     rt1     rt5     p50     p90     \u001b[11;1H                              0       0       0.00    0.00    0.00    0.00    \u001b[8;35H:/\u001b[8;38Hef83-3-20-2\u001b[8;50H9-2\u001b[8;54H9.ngrok.io -> ht\u001b[8;71Hp:/\u001b[8;75Hlocalh\u001b[9;1HForwarding                    https://ef83-3-20-229-229.ngrok.io -> http://local\u001b[m\u001b[38;5;16m\u001b[48;5;16m\u001b[10;1H                                                                              \u001b[m\u001b[38;5;7m\u001b[48;5;16m\u001b[11;1HConnections\u001b[11;31Httl\u001b[11;39Hopn\u001b[11;47Hrt1 \u001b[11;55Hrt5 \u001b[11;63Hp5\u001b[11;66H \u001b[11;71Hp9\u001b[11;74H \u001b[12;1H                              0       0       0.00    0.00    0.00    0.00    \u0002\u0007\u001b[m\u001b[H\u001b[2J\u001b[2J\u001b[?47l\u001b8\u001b[?1l\u001b>\u001b[?1006l\u001b[?1015l\u001b[?1002l\u001b[?1000l"
     ]
    }
   ],
   "source": [
    "!ngrok http -host-header=rewrite localhost:8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWNd0jofKttT",
    "outputId": "e3bf46cb-3de2-443a-a976-dd6f5ce46f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Public URL: http://7c47-3-20-229-229.ngrok.io\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [497]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     2607:fb90:8a80:96e9:31b2:ef33:e5e8:27d4:0 - \"GET /index HTTP/1.1\" 200 OK\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     172.58.180.187:0 - \"POST /items HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import torch\n",
    "from typing import Union\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from typing import TypeVar\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "\n",
    "dev_tok_model = cpu_model()\n",
    "tokenizer = dev_tok_model[1]\n",
    "model = dev_tok_model[2]\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class Result:\n",
    "    def __init__(self, ok: bool, value: T = None, error: str = \"\"):\n",
    "        self.ok = ok\n",
    "        # If the result is ok, set the value. Otherwise, set the error\n",
    "        self.value = value if ok else None\n",
    "        self.error = error if not ok else \"\"\n",
    "\n",
    "    def __str__(self):\n",
    "        # If the result is ok, return the value. Otherwise, return the error\n",
    "        return f\"Ok: {self.value}\" if self.ok else f\"Err: {self.error}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def is_ok(self):\n",
    "        return self.ok\n",
    "\n",
    "    def is_err(self):\n",
    "        return not self.ok\n",
    "\n",
    "    def unwrap(self):\n",
    "        if self.is_ok():\n",
    "            return self.value\n",
    "        else:\n",
    "            raise Exception(self.error)\n",
    "\n",
    "    def match(self, ok_func, err_func):\n",
    "        if self.is_ok():\n",
    "            return ok_func(self.value)\n",
    "        else:\n",
    "            return err_func(self.error)\n",
    "\n",
    "    # func must return a Result\n",
    "    def flat_map(self, func):\n",
    "        if self.is_ok():\n",
    "            return func(self.value)\n",
    "        else:\n",
    "            return self\n",
    "\n",
    "\n",
    "is_youtube_regex = re.compile(r\"https?://(www\\.)?youtube\\.com\")\n",
    "\n",
    "\n",
    "def is_youtube(link: str) -> bool:\n",
    "    \"\"\"Check if link is a YouTube link\"\"\"\n",
    "    return is_youtube_regex.match(link) is not None\n",
    "\n",
    "\n",
    "youtube_video_id_regex = re.compile(r\"https?://(?:(?:(?:www\\.youtube\\.com|m\\.youtube\\.com)/watch\\?v=([0-9A-Za-z_-]{10}[048AEIMQUYcgkosw]).*)|(?:youtu\\.be/([0-9A-Za-z_-]{10}[048AEIMQUYcgkosw])))\")\n",
    "\n",
    "\n",
    "def get_youtube_video_id(link: str) -> Result:\n",
    "    \"\"\"Get the video id from a YouTube link\"\"\"\n",
    "    if not is_youtube(link):\n",
    "        return Result(False, error=\"Not a youtube link\")\n",
    "    match = youtube_video_id_regex.match(link)\n",
    "    if match is None:\n",
    "        return Result(False, error=\"Invalid youtube link\")\n",
    "    return Result(True, value=match.group(1))\n",
    "\n",
    "\n",
    "def get_transcript(video_id: str) -> Result:\n",
    "    try:\n",
    "        text = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        # We need to transform the transcript into a string\n",
    "        return Result(True, value=\" \".join([line[\"text\"] for line in text]))\n",
    "    except Exception as e:\n",
    "        return Result(False, error=str(e))\n",
    "\n",
    "\n",
    "def get_summary(text: str, gen) -> Result:\n",
    "    # Gen must be a transformers pipeline\n",
    "    try:\n",
    "        prompt = text + \"\\n TLDR: \"\n",
    "        # WARNING: This is designed around gpt-neo-125M, which can be called in the following way\n",
    "        # Other models may require different parameters, and different ways of obtaining the summary\n",
    "        # Read through the documentation of the models for proper usage\n",
    "        summary = gen(prompt, do_sample=True, temperature=0.9, max_new_tokens=200)[0][\"generated_text\"]\n",
    "        return Result(True, value=summary[len(prompt):].strip())\n",
    "    except Exception as e:\n",
    "        return Result(False, error=str(e))\n",
    "\n",
    "\n",
    "def link_to_summary(link: str, gen) -> Result:\n",
    "    return get_youtube_video_id(link) \\\n",
    "        .flat_map(get_transcript) \\\n",
    "        .flat_map(lambda text: get_summary(text, gen))\n",
    "\n",
    "\n",
    "def link_to_transcript(link: str) -> Result:\n",
    "    return get_youtube_video_id(link) \\\n",
    "        .flat_map(get_transcript)\n",
    "\n",
    "\n",
    "def link_to_prompt(link: str) -> Result:\n",
    "    return get_youtube_video_id(link) \\\n",
    "        .flat_map(get_transcript) \\\n",
    "        .flat_map(lambda text: Result(True, value=text + \"\\n TLDR: \"))\n",
    "\n",
    "\n",
    "def unwrap_result(result: Result):\n",
    "    if result.is_ok():\n",
    "        return result.value\n",
    "    else:\n",
    "        raise Exception(result.error)\n",
    "\n",
    "\n",
    "def main(link):\n",
    "    #['audio-classification', 'automatic-speech-recognition', 'conversational', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'ner', 'object-detection', 'question-answering', \n",
    "    #'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'zero-shot-classification', 'translation_XX_to_YY']\n",
    "    pipe = pipeline('text-generation', model='EleutherAI/gpt-neo-125M')\n",
    "    result = link_to_summary(link, pipe)\n",
    "    return result\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get('/index')\n",
    "async def home():\n",
    "  result = main('https://www.youtube.com/watch?v=P7yM0TKvUm4')\n",
    "  return result\n",
    "\n",
    "class Item(BaseModel):\n",
    "    id: Union[int, None] = None\n",
    "    link: str\n",
    "    summary: Union[str, None] = None\n",
    "    rating: Union[int, None] = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.post(\"/items\")\n",
    "async def getInformation(item : Request):\n",
    "    req_info = await item.json()\n",
    "    # persist id\n",
    "    # delete link\n",
    "    # retreive summary\n",
    "    # keep same rating.\n",
    "    print(type(req_info))\n",
    "    link = req_info['link']\n",
    "    summary = main(link)\n",
    "    req_info['summary'] = summary\n",
    "    return {\n",
    "        \"status\" : \"SUCCESS\",\n",
    "        \"data\" : req_info,\n",
    "        \"type\" : str(type(req_info))\n",
    "    }\n",
    "# @app.post(\"/items/\")\n",
    "# async def create_item(item: Item):\n",
    "#     return item\n",
    "\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VcM_hNwOO16c",
    "outputId": "18e25262-7b70-4764-c2d5-806a4b770645"
   },
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "raw_data = YouTubeTranscriptApi.get_transcript(\"P7yM0TKvUm4\")\n",
    "\n",
    "# print(raw_data)\n",
    "type(raw_data)\n",
    "# first part of transcript data\n",
    "print(raw_data[0][\"text\"])\n",
    "text = \"\"\n",
    "lis_text = []\n",
    "for i, e in enumerate(raw_data):\n",
    "  lis_text.append(raw_data[i][\"text\"])\n",
    "# list to string\n",
    "text = ''.join(lis_text)\n",
    "print(text)\n",
    "\n",
    "\n",
    "\n",
    "prompt = text + \"\\n TLDR:\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids #.cuda() # .cuda() is for gpu, remove if not needed, gpt-j-6b needs gpu.\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "\n",
    "    input_ids,\n",
    "\n",
    "    do_sample=True,\n",
    "\n",
    "    temperature=0.9,\n",
    "\n",
    "    max_length=2000,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXPW319sPyyb"
   },
   "source": [
    "FROM THE ABOVE: we print the type and len of input_ids because unsure what it does\n",
    "\n",
    "FROM THE ABOVE: .cuda() function uses our gpu, (if you delete it, code might still work?)\n",
    "\n",
    "BELOW: print gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzsM9tNNPrmr"
   },
   "outputs": [],
   "source": [
    "print(type(input_ids))\n",
    "print(len(input_ids))\n",
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emb4Mqc7Px9-"
   },
   "source": [
    "# Things that need doing...?\n",
    "\n",
    "For App:\n",
    "- Ability to make API call to this model\n",
    "- Ability to append Summaries to database\n",
    "\n",
    "For Experiments:\n",
    "- Code that lets us loop through our summaries\n",
    "- Metrics for different models? Many metrics for same model? Different prompts?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
